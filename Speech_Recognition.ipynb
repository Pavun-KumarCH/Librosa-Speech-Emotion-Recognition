{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPMpCgJF9akF0TdBCaryUXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavun-KumarCH/Librosa-Speech-Emotion-Recognition/blob/main/Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech emotion Recognition Using Machine Learning"
      ],
      "metadata": {
        "id": "scrQsni0ODFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor Flow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense, BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "_N6Ppu4gVeS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBN45tTXN9mx"
      },
      "outputs": [],
      "source": [
        "# import all required libraries\n",
        "import pandas as pd # Data Manuplualtion\n",
        "import numpy as np # Arrays Calculation\n",
        "import glob #  file directories\n",
        "import soundfile # soundfile format\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import librosa for audio analysis"
      ],
      "metadata": {
        "id": "gqtlyYWFOcyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import plotly.express as px\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "OtgNY9iIOWNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "c_Pi4gwlPn05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "wV8o2Lb1PHtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "qyTis0wzPqeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Errors filter\n"
      ],
      "metadata": {
        "id": "Zn06edUJP8I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings('ignore',category = DeprecationWarning)\n"
      ],
      "metadata": {
        "id": "dDQnaoHNQlHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the RAVDESS Dataset"
      ],
      "metadata": {
        "id": "zbJaUzf3a_4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAV = '/Users/pavankumar/Downloads/archive/audio_speech_actors_01-24/'\n",
        "list_dir = os.listdir(RAV)\n",
        "\n",
        "list_dir.remove('.DS_Store')"
      ],
      "metadata": {
        "id": "cqJRuI2e0Cbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segregate the data according to the relavent sections"
      ],
      "metadata": {
        "id": "L6huY5gkbWhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = []\n",
        "gender = []\n",
        "path = []\n",
        "for i in list_dir:\n",
        "  fname = os.listdir(RAV + i)\n",
        "  for f in fname:\n",
        "    part = f.split('.')[0].split('-')\n",
        "    emotion.append(int(part[2]))\n",
        "    temp = int(part[6])\n",
        "    if temp % 2 == 0 :\n",
        "      temp = 'Female'\n",
        "    else:\n",
        "      temp = 'Male'\n",
        "    gender.append(temp)\n",
        "    path.append(RAV + i + '/' + f)"
      ],
      "metadata": {
        "id": "RJ5E_rE-1RAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(emotion, columns = ['Emotion'])\n",
        "data.value_counts()\n",
        "emotion_mapping = {1 : \"Neutral\",\n",
        "                   2 : 'Neutral',\n",
        "                   3 : 'Happy',\n",
        "                   4 : 'Sad',\n",
        "                   5 : 'Anger',\n",
        "                   6 : 'Fear',\n",
        "                   7 : 'Disgust',\n",
        "                   8 : 'Suprise'}\n",
        "data = data['Emotion'].replace(emotion_mapping)\n",
        "data = pd.concat([pd.DataFrame(gender, columns = ['Gender']), data, pd.DataFrame(path, columns = ['Path'])], axis = 1)\n",
        "data\n",
        "\n",
        "data['Labels'] = data['Gender'] + '_' + data['Emotion']\n",
        "data.drop(['Gender'], axis = 1, inplace = True)\n",
        "\n",
        "data['Labels'].value_counts()"
      ],
      "metadata": {
        "id": "Y0LscFqnAZw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "ZPo-K0ge3zvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "wl5p7NJp4A7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "MHFuVM7r4qab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'colab'\n",
        "\n",
        "px_fig = px.histogram(data, x = 'Emotion', color = 'Emotion', marginal= 'box',title = 'Emotion Count')\n",
        "px_fig.update_layout(bargap = 0.2)\n",
        "px_fig.show()\n",
        "\n",
        "px_fig = px.histogram(data, x = 'Labels', color = 'Emotion', marginal = 'box', title = 'Label Count')\n",
        "px_fig.update_layout(bargap = 0.2)\n",
        "px_fig.show()"
      ],
      "metadata": {
        "id": "K1V78Ff74ddD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_waveplot(meta, sr, e):\n",
        "  plt.figure(figsize = (10,3))\n",
        "  plt.title(\"Waveplot for audio with {} emotion\".format(e),size = 15)\n",
        "  librosa.display.waveshow(meta, sr = sr)\n",
        "  plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "2GRQ0Gkm8eMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spectrogram(meta, sr, e):\n",
        "  X = librosa.stft(meta)\n",
        "  Xdb = librosa.amplitude_to_db(abs(X))\n",
        "  plt.figure(figsize = (12, 3))\n",
        "  plt.title('Spectrogram for audio with {} emotion'.format(e), size =15)\n",
        "  librosa.display.specshow(Xdb, sr =sr, x_axis = 'time', y_axis = 'hz')\n",
        "  plt.colorbar()"
      ],
      "metadata": {
        "id": "xvpmZDjg9Dl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Emotion = 'Fear'\n",
        "path = np.array(data.Path[data.Emotion==Emotion])[1]\n",
        "meta, sampling_rate = librosa.load(path)\n",
        "\n"
      ],
      "metadata": {
        "id": "WiBTGpwS-CcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_waveplot(meta, sampling_rate, Emotion)\n",
        "create_spectrogram(meta, sampling_rate, Emotion)\n",
        "ipd.Audio(path)"
      ],
      "metadata": {
        "id": "XD7m4W4zDF98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "b76rJVxsFBGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(meta):\n",
        "  noise_amp = 0.035*np.random.uniform()*np.amax(meta)\n",
        "  meta = meta + noise_amp*np.random.normal(size = meta.shape[0])\n",
        "  return meta\n",
        "\n",
        "def stretch(meta, rate = 0.8):\n",
        "  return librosa.effects.time_stretch(meta, rate = rate)\n",
        "\n",
        "def shift(meta):\n",
        "  shift_range = int(np.random.uniform(low = 5, high = 5)*1000)\n",
        "  return np.roll(meta, shift_range)\n",
        "\n",
        "def pitch(meta, sampling_rate, pitch_factor = 0.7):\n",
        "  return librosa.effects.pitch_shift(meta, sr = sampling_rate, n_steps = pitch_factor)\n",
        "\n",
        "# Taking anf Example and checking for techniques\n",
        "path = np.array(data.Path)[1]\n",
        "meta, sample_rate = librosa.load(path)\n"
      ],
      "metadata": {
        "id": "HBoMZgquE-KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Audio"
      ],
      "metadata": {
        "id": "RTrh2b7WqwSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (14, 4))\n",
        "librosa.display.waveshow(y = meta, sr = sample_rate)\n",
        "ipd.Audio(path)"
      ],
      "metadata": {
        "id": "6zFMp6Rto_PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise Injection :"
      ],
      "metadata": {
        "id": "Z6LZo-oSq1h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = noise(meta)\n",
        "plt.figure(figsize = (14, 4))\n",
        "librosa.display.waveshow(y = x, sr = sample_rate)\n",
        "ipd.Audio(x, rate = sample_rate)"
      ],
      "metadata": {
        "id": "Hzn6gKveq0eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stretching"
      ],
      "metadata": {
        "id": "K0LQiQV_rIz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = stretch(meta)\n",
        "plt.figure(figsize = (14, 4))\n",
        "librosa.display.waveshow(y = x, sr = sample_rate)\n",
        "ipd.Audio(x, rate = sample_rate)"
      ],
      "metadata": {
        "id": "pxDKyzUOrNpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shifting"
      ],
      "metadata": {
        "id": "s03st7q4rl7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = shift(meta)\n",
        "plt.figure(figsize = (14, 4))\n",
        "librosa.display.waveshow(y = x, sr = sample_rate)\n",
        "ipd.Audio(x, rate = sample_rate)"
      ],
      "metadata": {
        "id": "xiVr3SUfroJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pitch"
      ],
      "metadata": {
        "id": "9ohaKlI0r7wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pitch(meta, sample_rate)\n",
        "plt.figure(figsize = (14, 4))\n",
        "librosa.display.waveshow(y = x, sr = sample_rate)\n",
        "ipd.Audio(x, rate = sample_rate)"
      ],
      "metadata": {
        "id": "aaVbH7hvr-1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "R87zDatvBsNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(meat):\n",
        "  # ZCR\n",
        "  result = np.array([])\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(y = meat).T, axis = 0)\n",
        "  result = np.hstack((result,zcr)) # stacking horizantally\n",
        "  # chroma_stft\n",
        "  stft = np.abs(librosa.stft(meta))\n",
        "  chroma_stft = np.mean(librosa.feature.chroma_stft(S = stft, sr = sample_rate).T, axis = 0)\n",
        "  result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "  # MFCC\n",
        "  mfcc = np.mean(librosa.feature.mfcc(y = meat, sr = sample_rate).T, axis  = 0)\n",
        "  result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "\n",
        "  # Root Mean Square Value\n",
        "  rms = np.mean(librosa.feature.rms(y = meta).T, axis = 0)\n",
        "  result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "  # Melspectrogram\n",
        "  mel = np.mean(librosa.feature.melspectrogram(y = meat, sr = sample_rate).T, axis = 0)\n",
        "  result  = np.hstack((result, mel))  # stacking horizontally\n",
        "  return result\n",
        "\n",
        "def get_feature(path):\n",
        "\n",
        "  meta ; sample_rate = librosa.load(path, duration = 2.5, offset = 0.6)\n",
        "  res1 = extract_features(meta)\n",
        "  result = np.array(res1)\n",
        "\n",
        "  noise_meat = noise(meat)\n",
        "  res2 = extract_features(noise_meat)\n",
        "  result = np.vstack((result, res2)) # stacking vertically\n",
        "\n",
        "  # data with strtching and pitching\n",
        "  new_meta = stretch(meta)\n",
        "  data_stretch_pitch = pitch(new_meta, sample_rate)\n",
        "  res3 = extract_features(data_stretch_pitch)\n",
        "  result = np.vstack((result, res3))\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "dxeqlzkgBphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "wF_GvO1GFOio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "for path , emotion in zip(data.Path, data.Emotion):\n",
        "  feature = get_features(path)\n",
        "  for ele in feature:\n",
        "    X.append(ele)\n",
        "    Y.append(emotion)\n",
        ""
      ],
      "metadata": {
        "id": "m3pgw6r4FQkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y), data.Path.shape"
      ],
      "metadata": {
        "id": "EDX9JXz5Jo0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature = pd.DataFrame(X)\n",
        "Feature['Labels'] = Y\n",
        "Feature.to_csv('features.csv', index = False)"
      ],
      "metadata": {
        "id": "WY5N7YRqJxXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Feature.head())\n",
        "display(Feature.describe())"
      ],
      "metadata": {
        "id": "SB6qnNuUKGWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperate Input and Output Variables"
      ],
      "metadata": {
        "id": "6Smv0IwiKzjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = Feature.iloc[:, :- 1].values\n",
        "Y = Feature['Labels'].values"
      ],
      "metadata": {
        "id": "iudy6_RJKn0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
      ],
      "metadata": {
        "id": "Cfhiw8xXKzMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into Train and Test"
      ],
      "metadata": {
        "id": "lvcxLRmjLJfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test  = train_test_split(X, Y, shuffle = True, random_state = 0 )\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "BHCvM_mJLI7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "x_train = scalar.fit_transform(x_train)\n",
        "x_test = scalar.transform(x_test)\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "xuGjCyNBL41V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "nwWTdN8wMiwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "       # Block 1\n",
        "       Conv1D(256, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu', input_shape = (x_train.shape[1], 1)),\n",
        "       MaxPooling1D(pool_size = 5, strides = 2, padding = 'same'),\n",
        "\n",
        "       # Block 2\n",
        "       Conv1D(128, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
        "       MaxPooling1D(pool_size = 5, strides = 2, padding = 'same'),\n",
        "\n",
        "       # Block 3\n",
        "       Conv1D(64, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
        "       MaxPooling1D(pool_size = 5, strides = 2, padding = 'same'),\n",
        "       Dropout(0.2),\n",
        "\n",
        "       # Block 4\n",
        "       Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
        "       MaxPooling1D(pool_size = 5, strides = 2, padding = 'same'),\n",
        "\n",
        "       Flatten(),\n",
        "       Dense(units= 16, activation = 'relu'),\n",
        "       Dropout(0.3),\n",
        "       Dense(units = 7, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ILETTYj5MiOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "pddsfLVjQlSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rlrp = ReduceLROnPlateau(monitor = 'loss', factor = 0.4, verbose = 0, patience = 4, min_lr = 0.0000001)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 51, validation_data = (x_test, y_test), callbacks = [rlrp])"
      ],
      "metadata": {
        "id": "uKgsEsugQk7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "gXlR7iFBXwkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Accuracy of our model on Test data :\", model.evaluate(x_test, y_test)[1]*100,'%')\n",
        "\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "epochs = [i for i in range(51)]\n",
        "\n",
        "fig, ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "test_acc = history.history['val_accuracy']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20,6)\n",
        "ax[0].plot(epochs, train_loss, label = 'Training Loss', marker = 'o', linewidth = 2)\n",
        "ax[0].plot(epochs, test_loss, label = 'Testing Loss', marker = '.', linewidth = 2)\n",
        "ax[0].set_title('Training & Testing Loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(epochs, train_acc, label = 'Training Accuracy', marker = 'o', linewidth = 2)\n",
        "ax[1].plot(epochs, test_acc, label = 'Testing Accuracy', marker = '.', linewidth = 2)\n",
        "ax[1].set_title('Trainig & Testing Accuracy')\n",
        "ax[1].legend()"
      ],
      "metadata": {
        "id": "tfMGSUZIUpQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n"
      ],
      "metadata": {
        "id": "QbCRB9XfX4_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = model.predict(x_test)\n",
        "y_pred = encoder.inverse_transform(pred_test)\n",
        "y_test = encoder.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "Xo3d5hNZXyni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.DataFrame(columns = ['Predicted Labels', 'Actual Labels'])\n",
        "final_data['Predicted Labels'] = y_pred.flatten()\n",
        "final_data['Actual Labels'] = y_test.flatten()\n",
        "\n",
        "display(final_data.head())"
      ],
      "metadata": {
        "id": "KO_-ZkJNYSm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "x_dVWKFDYz1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize = (12, 10))\n",
        "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
        "sns.heatmap(cm, linecolor='white', cmap='Purples', linewidth=1, annot=True, fmt='')\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Labels', size=14)\n",
        "plt.ylabel('Actual Labels', size=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IIOnw8qKY-tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize = (12, 10))\n",
        "cm = pd.DataFrame(cm, index = [i for i in encoder.categories_], columns = [i for i in encoder.categories_])\n",
        "sns.heatmap(cm, linecolor='white', cmap = 'Purples', linewidths = 1, annot = True, fmt = '')\n",
        "plt.title('Confusion Matrix', size = 20)\n",
        "plt.xlabel('Predicted Labels', size = 14)\n",
        "plt.ylabel('Actual Labels', size = 14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cz4Be325YxFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "m9oKTz5uZpXn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}